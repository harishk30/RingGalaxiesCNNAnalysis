{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN",
      "provenance": [],
      "mount_file_id": "1BE_fEtQU14HQSiOQ6Y5qkwm0JmdHL5dg",
      "authorship_tag": "ABX9TyOEsyr0LDPD6aZ3bZIy8857",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harishk30/RingGalaxiesCNNAnalysis/blob/main/GAN/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "R9uOHMdID2QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "zPFOEcKxGzqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory = '/content/drive/MyDrive/FinalRing', label_mode = None, image_size = (64, 64), batch_size = 32, shuffle = True\n",
        ").map(lambda x: x/255.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJE_tf_tB_CZ",
        "outputId": "e3bbde0b-f066-4e6f-941c-774c25e70e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1437 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers "
      ],
      "metadata": {
        "id": "AMBTNivvHVd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = (64, 64, 3)),\n",
        "     layers.Conv2D(64, kernel_size = 4, strides = 2, padding = \"same\"),\n",
        "     layers.LeakyReLU(0.2),\n",
        "     layers.Conv2D(128, kernel_size = 4, strides = 2, padding = \"same\"),\n",
        "     layers.LeakyReLU(0.2),\n",
        "     layers.Conv2D(128, kernel_size = 4, strides = 2, padding = \"same\"),\n",
        "     layers.LeakyReLU(0.2),\n",
        "     layers.Flatten(),\n",
        "     layers.Dropout(0.2),\n",
        "     layers.Dense(1, activation = \"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(discriminator.summary())\n",
        "\n",
        "latent_dim = 128\n",
        "generator = keras.Sequential (\n",
        "    [\n",
        "     layers.Input(shape = (latent_dim,)),\n",
        "     layers.Dense(8*8*128),\n",
        "     layers.Reshape((8, 8, 128)),\n",
        "     layers.Conv2DTranspose(128, kernel_size = 4, strides = 2, padding = \"same\"),\n",
        "     layers.LeakyReLU(0.2),\n",
        "     layers.Conv2DTranspose(256, kernel_size = 4, strides = 2, padding = \"same\"),\n",
        "     layers.LeakyReLU(0.2),\n",
        "     layers.Conv2DTranspose(512, kernel_size = 4, strides = 2, padding = \"same\"),\n",
        "     layers.LeakyReLU(0.2),\n",
        "     layers.Conv2D(3, kernel_size = 5, padding = \"same\", activation = \"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(generator.summary())\n",
        "\n",
        "opt_gen = tf.keras.optimizers.Adam(1e-4)\n",
        "opt_disc = tf.keras.optimizers.Adam(1e-4)\n",
        "loss_fn = keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyTbIc0FCalc",
        "outputId": "c048d1f1-aec6-4857-925f-ec664f79dce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 8192)              1056768   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Mjkurq1_HtNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  for idx, real in enumerate(tqdm(dataset)):\n",
        "    batch_size = real.shape[0]\n",
        "    random_latent_vectors = tf.random.normal(shape = (batch_size, latent_dim))\n",
        "    \n",
        "    fake = generator(random_latent_vectors)\n",
        "\n",
        "    if idx % 5 == 0:\n",
        "      img = keras.preprocessing.image.array_to_img(fake[0])\n",
        "      img.save(f\"/content/generated_images/generated_img{epoch}_{idx}_.png\")\n",
        "\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "      loss_disc_real = loss_fn(tf.ones((batch_size, 1)), discriminator(real))\n",
        "      loss_disc_fake = loss_fn(tf.zeros(batch_size, 1), discriminator(fake)) \n",
        "      loss_disc = (loss_disc_real + loss_disc_fake)/2\n",
        "    \n",
        "    grads = disc_tape.gradient(loss_disc, discriminator.trainable_weights)\n",
        "    opt_disc.apply_gradients(\n",
        "        zip(grads, discriminator.trainable_weights)\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      fake = generator(random_latent_vectors)\n",
        "      output = discriminator(fake)\n",
        "      loss_gen = loss_fn(tf.ones(batch_size, 1), output)\n",
        "\n",
        "    grads = gen_tape.gradient(loss_gen, generator.trainable_weights)\n",
        "    opt_gen.apply_gradients(\n",
        "        zip(grads, generator.trainable_weights)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB2ctKlREZRM",
        "outputId": "b4bb337c-2cdb-4cec-f3aa-4db60cb9e4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45/45 [00:10<00:00,  4.38it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.14it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.15it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.04it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.07it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.11it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.20it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.98it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.01it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.96it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.10it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.17it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.13it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.96it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.07it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.04it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.20it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.12it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.07it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.12it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.03it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.11it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.10it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.15it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.05it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.98it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.97it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.96it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.93it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.98it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.89it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.04it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.98it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.05it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.14it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.16it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.39it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.20it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.07it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.21it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.27it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.15it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.12it/s]\n",
            "100%|██████████| 45/45 [02:21<00:00,  3.15s/it]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.11it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.39it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.89it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.97it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.08it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  7.99it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.05it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.12it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.40it/s]\n",
            "100%|██████████| 45/45 [00:05<00:00,  8.03it/s]\n"
          ]
        }
      ]
    }
  ]
}